{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_ID\n",
       "104    79887\n",
       "101    59638\n",
       "105    35597\n",
       "99     25816\n",
       "102    14151\n",
       "73     10847\n",
       "74      5898\n",
       "100     5833\n",
       "72      5225\n",
       "127     1509\n",
       "128     1178\n",
       "69      1177\n",
       "129      935\n",
       "68       830\n",
       "71       685\n",
       "126       47\n",
       "70         9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Product_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating conditional columns based on usage_Type for the 'Volume_KB_SC_Nbr'\n",
    "data['Volume_KB_Data'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] == 'DATA' else 0, axis=1)\n",
    "data['Volume_SC_Voice'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] == 'VOICE' else 0, axis=1)\n",
    "data['Nb_Usage_Others'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] not in ['VOICE', 'DATA'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for 'usage_Type' and 'Destination'\n",
    "usage_type_dummies = pd.get_dummies(data['usage_Type'], prefix='Type')\n",
    "destination_dummies = pd.get_dummies(data['Destination'], prefix='Dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate these new dummy variables with the main dataframe\n",
    "data = pd.concat([data, usage_type_dummies, destination_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SUBSCRIPTION_DATE', 'subscribers', 'Product_ID', 'NB_SUBSCRIPTION',\n",
       "       'USAGE_DATE', 'usage_Type', 'Destination', 'Amount_DZD',\n",
       "       'Amount_data_DZD', 'Volume_Data_KB', 'Volume_KB_SC_Nbr', 'Nb_USAGE',\n",
       "       'Ines', 'Volume_KB_Data', 'Volume_SC_Voice', 'Nb_Usage_Others',\n",
       "       'Type_DATA', 'Type_SMS', 'Type_Transfert credit', 'Type_VAS',\n",
       "       'Type_VOICE', 'Dest_DATA', 'Dest_FIX', 'Dest_Internationnal',\n",
       "       'Dest_OFF-NET', 'Dest_ON-NET', 'Dest_Others', 'Dest_Transfert credit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = data.groupby(['Product_ID', 'subscribers', 'SUBSCRIPTION_DATE']).agg({\n",
    "    'NB_SUBSCRIPTION': 'sum',\n",
    "    'Amount_DZD': 'sum',\n",
    "    'Amount_data_DZD': 'sum',\n",
    "    'Volume_Data_KB': 'sum',\n",
    "    'Volume_KB_Data': 'sum',\n",
    "    'Volume_SC_Voice': 'sum',\n",
    "    'Nb_Usage_Others': 'sum',\n",
    "    'Nb_USAGE': 'sum',\n",
    "    **{col: 'sum' for col in usage_type_dummies.columns},\n",
    "    **{col: 'sum' for col in destination_dummies.columns}\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data['SUBSCRIPTION_DATE'] = pd.to_datetime(\n",
    "    aggregated_data['SUBSCRIPTION_DATE'])\n",
    "aggregated_data['Year'] = aggregated_data['SUBSCRIPTION_DATE'].dt.year\n",
    "aggregated_data['Month'] = aggregated_data['SUBSCRIPTION_DATE'].dt.month\n",
    "aggregated_data['Day'] = aggregated_data['SUBSCRIPTION_DATE'].dt.day\n",
    "aggregated_data['DayOfWeek'] = aggregated_data['SUBSCRIPTION_DATE'].dt.dayofweek\n",
    "\n",
    "# Optionally, create cyclical features for month and day of week\n",
    "aggregated_data['Month_sin'] = np.sin(2 * np.pi * aggregated_data['Month']/12)\n",
    "aggregated_data['Month_cos'] = np.cos(2 * np.pi * aggregated_data['Month']/12)\n",
    "aggregated_data['DayOfWeek_sin'] = np.sin(2 * np.pi * aggregated_data['DayOfWeek']/7)\n",
    "aggregated_data['DayOfWeek_cos'] = np.cos(2 * np.pi * aggregated_data['DayOfWeek']/7)\n",
    "\n",
    "aggregated_data.drop(columns=['SUBSCRIPTION_DATE', 'subscribers', 'Month','Day'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_dummies = pd.get_dummies(aggregated_data['Year'], prefix='Year')\n",
    "aggregated_data = pd.concat(\n",
    "    [aggregated_data, year_dummies], axis=1)\n",
    "aggregated_data.drop(columns=['Year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated_data.drop(columns=['Amount_data_DZD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50775, 28)"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Product_ID', axis=1)\n",
    "y = data['Product_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-49 {color: black;}#sk-container-id-49 pre{padding: 0;}#sk-container-id-49 div.sk-toggleable {background-color: white;}#sk-container-id-49 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-49 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-49 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-49 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-49 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-49 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-49 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-49 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-49 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-49 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-49 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-49 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-49 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-49 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-49 div.sk-item {position: relative;z-index: 1;}#sk-container-id-49 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-49 div.sk-item::before, #sk-container-id-49 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-49 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-49 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-49 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-49 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-49 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-49 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-49 div.sk-label-container {text-align: center;}#sk-container-id-49 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-49 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-49\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" checked><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42  )\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100],  # Number of trees in the forest\n",
    "#     # Number of features to consider at every split\n",
    "#     'max_features': ['auto', 'sqrt'],\n",
    "#     'max_depth': [None, 10, 20, 30],   # Maximum number of levels in tree\n",
    "#     # Minimum number of samples required to split a node\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     # Minimum number of samples required at each leaf node\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup the grid search\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,           # Number of folds in cross-validation\n",
    "#     verbose=2,      # Controls the verbosity: the higher, the more messages\n",
    "#     n_jobs=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X, y)  # Replace X and y with your features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = grid_search\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    n_estimators=100, max_features='sqrt', random_state=42, min_samples_leaf=1, min_samples_split=2, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-50 {color: black;}#sk-container-id-50 pre{padding: 0;}#sk-container-id-50 div.sk-toggleable {background-color: white;}#sk-container-id-50 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-50 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-50 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-50 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-50 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-50 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-50 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-50 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-50 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-50 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-50 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-50 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-50 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-50 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-50 div.sk-item {position: relative;z-index: 1;}#sk-container-id-50 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-50 div.sk-item::before, #sk-container-id-50 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-50 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-50 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-50 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-50 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-50 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-50 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-50 div.sk-label-container {text-align: center;}#sk-container-id-50 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-50 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-50\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" checked><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the classifier\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9351058591826686\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          68       0.78      1.00      0.88        25\n",
      "          69       0.82      0.92      0.87        61\n",
      "          71       0.83      0.97      0.90        31\n",
      "          72       0.71      0.65      0.68       220\n",
      "          73       0.87      0.82      0.84       477\n",
      "          74       0.81      0.77      0.79       226\n",
      "          99       0.96      0.97      0.96      1146\n",
      "         100       0.96      1.00      0.98       218\n",
      "         101       0.99      0.98      0.98      2383\n",
      "         102       0.95      0.98      0.97       595\n",
      "         104       0.98      0.92      0.95      3267\n",
      "         105       0.91      0.95      0.93      1372\n",
      "         126       0.43      1.00      0.60         3\n",
      "         127       0.38      0.92      0.54        50\n",
      "         128       0.42      1.00      0.59        44\n",
      "         129       0.39      0.92      0.54        37\n",
      "\n",
      "    accuracy                           0.94     10155\n",
      "   macro avg       0.76      0.92      0.81     10155\n",
      "weighted avg       0.95      0.94      0.94     10155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/TestDJEZZY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating conditional columns based on usage_Type for the 'Volume_KB_SC_Nbr'\n",
    "data['Volume_KB_Data'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] == 'DATA' else 0, axis=1)\n",
    "data['Volume_SC_Voice'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] == 'VOICE' else 0, axis=1)\n",
    "data['Nb_Usage_Others'] = data.apply(\n",
    "    lambda x: x['Volume_KB_SC_Nbr'] if x['usage_Type'] not in ['VOICE', 'DATA'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for 'usage_Type' and 'Destination'\n",
    "usage_type_dummies = pd.get_dummies(data['usage_Type'], prefix='Type')\n",
    "destination_dummies = pd.get_dummies(data['Destination'], prefix='Dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate these new dummy variables with the main dataframe\n",
    "data = pd.concat([data, usage_type_dummies, destination_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = data.groupby(['subscribers', 'SUBSCRIPTION_DATE']).agg({\n",
    "    'NB_SUBSCRIPTION': 'sum',\n",
    "    'Amount_DZD': 'sum',\n",
    "    'Amount_data_DZD': 'sum',\n",
    "    'Volume_Data_KB': 'sum',\n",
    "    'Volume_KB_Data': 'sum',\n",
    "    'Volume_SC_Voice': 'sum',\n",
    "    'Nb_Usage_Others': 'sum',\n",
    "    'Nb_USAGE': 'sum',\n",
    "    **{col: 'sum' for col in usage_type_dummies.columns},\n",
    "    **{col: 'sum' for col in destination_dummies.columns}\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data['SUBSCRIPTION_DATE'] = pd.to_datetime(\n",
    "    aggregated_data['SUBSCRIPTION_DATE'])\n",
    "aggregated_data['Year'] = aggregated_data['SUBSCRIPTION_DATE'].dt.year\n",
    "aggregated_data['Month'] = aggregated_data['SUBSCRIPTION_DATE'].dt.month\n",
    "aggregated_data['Day'] = aggregated_data['SUBSCRIPTION_DATE'].dt.day\n",
    "aggregated_data['DayOfWeek'] = aggregated_data['SUBSCRIPTION_DATE'].dt.dayofweek\n",
    "\n",
    "# Optionally, create cyclical features for month and day of week\n",
    "aggregated_data['Month_sin'] = np.sin(2 * np.pi * aggregated_data['Month']/12)\n",
    "aggregated_data['Month_cos'] = np.cos(2 * np.pi * aggregated_data['Month']/12)\n",
    "aggregated_data['DayOfWeek_sin'] = np.sin(\n",
    "    2 * np.pi * aggregated_data['DayOfWeek']/7)\n",
    "aggregated_data['DayOfWeek_cos'] = np.cos(\n",
    "    2 * np.pi * aggregated_data['DayOfWeek']/7)\n",
    "\n",
    "save = aggregated_data.copy()\n",
    "aggregated_data.drop(columns=['SUBSCRIPTION_DATE', 'subscribers','Month','Day' ], inplace=True)\n",
    "\n",
    "year_dummies = pd.get_dummies(aggregated_data['Year'], prefix='Year')\n",
    "aggregated_data = pd.concat(\n",
    "    [aggregated_data, year_dummies], axis=1)\n",
    "aggregated_data.drop(columns=['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f = aggregated_data\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {'subscribers': save['subscribers'], 'Product_ID': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_ID\n",
       "101    726\n",
       "104    508\n",
       "99     198\n",
       "105     25\n",
       "102      9\n",
       "100      2\n",
       "73       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['Product_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1469"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df['subscribers'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subscriber_id' and 'Product_ID' and count occurrences\n",
    "product_counts = data.groupby(\n",
    "    ['subscribers', 'Product_ID', 'usage_Type', 'SUBSCRIPTION_DATE']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "def get_weight(usage_type):\n",
    "    if usage_type == 'DATA':\n",
    "        return 2\n",
    "    elif usage_type == 'VOICE' :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "product_counts['sort_weight'] = product_counts['usage_Type'].apply(get_weight)\n",
    "# Sort the data by 'subscriber_id' and 'counts' to put the highest counts at the top for each subscriber\n",
    "# Sort the data by 'subscribers', 'sort_weight' (descending), and 'counts' (descending)\n",
    "product_counts['SUBSCRIPTION_DATE'] = pd.to_datetime(\n",
    "    product_counts['SUBSCRIPTION_DATE'])\n",
    "product_counts_sorted = product_counts.sort_values(\n",
    "    by=['subscribers', 'sort_weight', 'SUBSCRIPTION_DATE', 'counts'], ascending=[True, False, False,False])\n",
    "\n",
    "# Drop duplicates to keep only the top (most frequent product) for each subscriber\n",
    "most_frequent_products = product_counts_sorted.drop_duplicates(\n",
    "    subset='subscribers', keep='first')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
